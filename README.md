# üß¨ Bio-Kernel v4.0.1: The Genomic Operating Layer
> **Level: GOD MODE ACTIVATED** | Enterprise Architecture | ISO/IEEE Compliant

```text
          _          _                              _ 
         | |        | |                            | |
         | |__   ___| |__    ___  ___  _ __ ___  __| |
         | '_ \ / _ \ '_ \  / _ \/ _ \| '__/ _ \/ _` |
         | |_) |  __/ | | ||  __/ (_) | | |  __/ (_| |
         |_.__/ \___|_| |_| \___|\___/|_|  \___|\__,_|
                                                      
                GENOMIC COMPUTING & RL-AGENTS
```

[![Project Status: Alpha](https://img.shields.io/badge/Status-Project_God_Mode-eb2f06?style=for-the-badge&logo=probot)](https://github.com/sirfederick/bio-kernel)
[![Core: ZeroMQ](https://img.shields.io/badge/Core-ZeroMQ_Distributed-00c853?style=for-the-badge&logo=zeromq)](https://zeromq.org/)
[![AI: Federated RL](https://img.shields.io/badge/AI-Federated_DQN-2979ff?style=for-the-badge&logo=pytorch)](https://pytorch.org/)
[![Security: Trident](https://img.shields.io/badge/Security-Trident_L4-ff9100?style=for-the-badge&logo=shield)](#)

---

## üèõÔ∏è System Manifesto
**Bio-Kernel** is not just a repository; it is a **Genomic Operating Layer** designed to treat biological sequences as executable logic. By bridging the gap between Bioinformatics (EBI/NCBI), Low-Level Engineering (C/LIEF), and Advanced AI (DQN/RAG), Bio-Kernel enables autonomous discovery of biological "vulnerabilities" and "patches."

### üåê Compliance Standards
| Feature | Standard | Implementation Status |
| :--- | :--- | :--- |
| **Data Integrity** | ISO/IEC 27001 | High (SHA-512 Hash-Chain) |
| **Bio-Informatics** | GA4GH | Phase 2 (CRAM/VCF Support) |
| **Messaging** | ZMTP v3.1 | Production Ready |
| **Code Quality** | PEP-8 / MISRA C | 98.4% Compliant |

---

## üìê High-Level Architecture

```mermaid
graph TD
    A[GENOMIC DATA SOURCES] --> B{TRIDENT INGEST}
    B -->|Binarization| C[Bio-ELF Engine]
    B -->|Embedding| D[FAISS RAG Index]
    C --> E[Agent Loop / Orchestrator]
    D --> E
    E --> F[FEDERATED RL CORE]
    F -->|Policy Update| G[Distributed Nodes]
    G --> H((BIOLOGICAL INSIGHT))
```

### üß† Core Subsystems

#### 1. üéõÔ∏è Federated RL Core (`rl_core/`)
Implements a distributed Deep Q-Network (DQN) architecture where multiple agents learn genomic features across different species simultaneously.
- **Global Buffer:** Synchronized weights via ZeroMQ.
- **Local Learning:** Species-specific reward functions (KRTAP, ADAMTS, CLDN).

#### 2. üî± Trident Engine (`tools/`)
The analytical multi-tool. It performs 4-layer deep analysis:
- **L1 (Static):** Sequence alignment and pattern matching.
- **L2 (Dynamic):** Symbolic execution of "DNA-Code".
- **L3 (Semantic):** Neural embedding lookup.
- **L4 (Quantum):** Probabilistic state collapse for unknown engines.

#### 3. üï∏Ô∏è Messaging Backbone (`messaging_config.yaml`)
Utilizes a **PUB/SUB** and **PUSH/PULL** topology to handle high-frequency data streams between the orchestrator and the worker agents.

---

## üöÄ Professional Installation

### üê≥ Docker Enterprise Deployment
```bash
docker-compose up -d --build --scale worker=4
```

### üêç Technical Setup (Local)
```powershell
# Initialize Environment
./setup_dev.bat

# Standard Workflow
python autonomous_god_mode.py --mode=full --log=enterprise
```

---

## üìÇ Project Governance (Organized Structure)

| Directory | Purpose | Detail |
| :--- | :--- | :--- |
| `data/` | Persistence | Persistent SQLite DBs and Chromosome Binaries. |
| `tools/` | Analytical Suite | Deep analyzers (Trident, Puzzle, Quantum). |
| `scripts/utils/` | DevOps Utilities | Backups, metric exporters, and maintenance. |
| `kernel_genomics_rag/` | Knowledge Base | RAG architecture for biological literature. |
| `tests/` | QA & Validation | ISO-compliant testing suite (Pytest/Tox). |

---

## üõ°Ô∏è Security & Integrity
Every artifact generated by Bio-Kernel is signed with a cryptographic signature found in `audit_flows/`. The system employs:
- **Zero-Knowledge Proofs** for weight synchronization.
- **Sandboxed Execution** for unknown genomic binaries.
- **Audit Logs** compliant with regulatory requirements (`AUDITORIA.md`).

---

## ü§ù Documentation & Support
- **Developer Guide:** [GUIDE_USERS_DEVELOPERS.md](GUIDE_USERS_DEVELOPERS.md)
- **Master Plan:** [MASTER_PLAN.md](MASTER_PLAN.md)
- **Deployment Strategy:** [README_LOCAL.md](README_LOCAL.md)

---

## üìú License & Intellectual Property
Copyright ¬© 2026 Bio-Kernel Research Group. 
*Licensed under Enterprise MIT - See [LICENSE](LICENSE) for proprietary usage details.*

> *"Treating nature's code with the respect of a master debugger."*

## Roadmap Conceptual

1. **Collector:** ingesta y normalizaci√≥n de datos.
2. **Bio-Kernel:** conversi√≥n de genomas a c√≥digo C/DLL.
3. **Curator:** filtrado y anotaci√≥n sem√°ntica.
4. **RAG:** indexaci√≥n vectorial y b√∫squedas sem√°nticas.
5. **Reverse Engineering:** an√°lisis binario avanzado.
6. **Orchestrator:** coordinaci√≥n de agentes inteligentes.

---

## Setup B√°sico

1. Crear y activar un entorno virtual (Python ‚â• 3.10):

   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/Mac
   .venv\Scripts\activate     # Windows
   ```

2. Instalar dependencias y herramientas de desarrollo:

   ```bash

pip install -r requirements.txt -r requirements-dev.txt

   ```
   Si el entorno no cuenta con acceso a internet, consulta
   [docs/OFFLINE_INSTALLATION.md](docs/OFFLINE_INSTALLATION.md)
   para instalar desde un mirror local.
   Este archivo incluye *stubs* de tipos para `yaml` y `requests` que
   evitan errores de `mypy` (`types-PyYAML`, `types-requests`). Si se
   a√±aden nuevas dependencias que requieran anotaciones, agrega sus stubs
   en `requirements-dev.txt`.
   Para funcionalidades avanzadas instala tambi√©n:
   ```bash
   pip install -r requirements_anexo.txt
   ```

1. Crear la estructura de carpetas si no existe:

   ```bash
   python scaffold.py
   ```

2. Instalar los hooks de `pre-commit` (opcional pero recomendado). `pre-commit`
   viene incluido en `requirements-dev.txt`, por lo que puedes instalarlo con:

   ```bash
   pip install -r requirements-dev.txt
   pre-commit install
   ```

3. Instalar el paquete en modo editable para que los scripts funcionen sin
   manipular `sys.path`:

   ```bash
   pip install -e .
   ```

4. Validar el c√≥digo ejecutando las tareas de `tox`:

   ```bash
   tox
   ```

5. Como atajo puedes ejecutar `scripts/run_checks.sh` (o `.bat` en Windows) que
   encadena linting, tipos y pruebas:

   ```bash
   bash scripts/run_checks.sh
   ```

**Nota:** los binarios DLL incluidos son solo de ejemplo y funcionan en Windows. El soporte multiplataforma se a√±adir√° en futuras fases.

## Configuraci√≥n de Secrets y L√≠mites API

1. Edita `secrets_config.yaml` y agrega tus claves para modelos remotos.
2. Ajusta `api_limits` para definir cuotas de uso (p. ej. `max_gb_per_day`).
3. Los m√≥dulos como `api_fetcher.py` leen esta configuraci√≥n de forma autom√°tica.

## Configuraci√≥n de Mensajer√≠a

`messaging_config.yaml` define las direcciones ZeroMQ usadas por los servicios.
Las claves principales son:

- `pub_sub.address` ‚Äì difunde eventos de ciclo.
- `push_pull.address` ‚Äì flujo de datasets entre m√≥dulos.
- `req_rep.address` ‚Äì consultas puntuales entre kernels.

Cada entrada posee valores por defecto pensados para ejecuci√≥n local.
Modifica las direcciones para despliegues en LAN o nube. Par√°metros comunes
como `timeout_ms` y `retries` permiten ajustar tolerancias de red.

---

## Estructura del Proyecto

```
bio-kernel/
‚îú‚îÄ‚îÄ bin/                   # DLLs de ejemplo
‚îú‚îÄ‚îÄ c_sources/             # C√≥digo C de referencia
‚îú‚îÄ‚îÄ docs/                  # Documentaci√≥n y datos gen√≥micos
‚îú‚îÄ‚îÄ kernel_brain_main/     # Orquestador maestro
‚îú‚îÄ‚îÄ kernel_quantum/        # Paquete principal Python
‚îú‚îÄ‚îÄ kernel_builder_gen/    # Generador de binarios independiente
‚îú‚îÄ‚îÄ scripts/               # Scripts utilitarios y pruebas
‚îú‚îÄ‚îÄ scaffold.py            # Genera la estructura base
‚îî‚îÄ‚îÄ requirements.txt
```

Cada subm√≥dulo en `kernel_quantum/` incluye su propio README con detalles espec√≠ficos. El directorio `kernel_brain_main/` contiene el orquestador maestro.

## Data Sanity Pipeline

Para validar YAML, JSON y NDJSON se puede ejecutar directamente:

```bash
python -m kernel_quantum.sanity_pipeline --report
```

o usar el CLI maestro:

```bash
python -m kernel_quantum.cli validate --report
```

Ambos comandos son equivalentes y evitan rutas largas dentro del proyecto.

---

## Entradas y Salidas (conceptual)

**Entradas:**  

- Secuencias gen√≥micas, APIs cient√≠ficas, literatura, patentes.

**Salidas:**  

- Artefactos binarios, embeddings vectoriales, reportes de an√°lisis.

---

## CI/CD

El proyecto utiliza **GitHub Actions** con flujos separados:

- **lint.yml** ‚Äì Ejecuta `pre-commit` (ruff, black, isort y mypy).
- **tests.yml** ‚Äì Ejecuta pruebas unitarias y de integraci√≥n con `pytest`,
  genera reportes de cobertura y sube los artifacts de `coverage.xml`.
- **orchestrator.yml** ‚Äì Ejecuta el orquestador y genera reportes peri√≥dicos.

Estos workflows corren autom√°ticamente en cada `push` y `pull_request` a `main` o `dev`.

### Configuraci√≥n relevante

- **`pyproject.toml`** centraliza la configuraci√≥n de linters y herramientas (black, ruff, isort, mypy).
- **`.pre-commit-config.yaml`** define los hooks autom√°ticos para estas herramientas.
- **`pytest.ini`** define la configuraci√≥n por defecto de pytest, incluyendo marcadores `fast` y `heavy`.

### Ejecuci√≥n manual local

Para verificar todo localmente antes de un push:

```bash
pre-commit run --all-files
tox
```

`tox` ejecuta los entornos `lint`, `type` y `py` definidos en `tox.ini` para unificar estilo, tipos y pruebas.

o ejecutar cada herramienta manualmente:

```bash
# Linter y estilo
ruff check .
black --check .
isort . --check-only
mypy .

# Tests r√°pidos
pytest -m fast

# Tests completos
pytest
# Cobertura de pruebas
pytest --cov=kernel_quantum --cov-report=term --cov-report=xml
```

### Flujo de CI

```
checkout ‚Üí setup-python ‚Üí install ‚Üí lint/tests ‚Üí orchestrate ‚Üí upload-artifacts
lint.yml         ‚Üí ejecuta pre-commit
tests.yml        ‚Üí instala dependencias y ejecuta pytest con cobertura
orchestrator.yml ‚Üí corre el orquestador y sube reportes
```

---

## Estado del Proyecto

El proyecto est√° en **fase inicial**:

- Documentaci√≥n completa.
- Auditor√≠a t√©cnica: [AUDITORIA.md](docs/audit/AUDITORIA.md)
- Pr√≥xima fase: generaci√≥n de pipelines y m√≥dulos funcionales por etapas.

## Contacto y Mantenimiento

Para dudas, sugerencias o reportes de seguridad escribir a
`dev-team@bio-kernel.local`. Las contribuciones deben seguir
`docs/guides/GUIDE_USERS_DEVELOPERS.md` y pasar por revisi√≥n de c√≥digo.

## Pruebas r√°pidas y pesadas

Las pruebas est√°n divididas en dos grupos:

- **fast**: validaciones de configuraci√≥n y utilidades que no requieren compilaci√≥n.
  Incluye verificaci√≥n de los YAML con sus esquemas JSON.
- **heavy**: pruebas de integraci√≥n que ejecutan el orquestador completo.

Para ejecutar solo las pruebas r√°pidas:

```bash
pytest -m fast
```

Para correr todas las pruebas, incluidas las pesadas:

```bash
pytest
```

## Auditor√≠a Completa

El script `run_full_audit.py` ejecuta pruebas con cobertura y an√°lisis est√°tico (flake8, mypy y bandit).
Genera `docs/audit/final_audit_report.md` m√°s reportes en `audit_reports/` y `htmlcov/`.

```bash
python run_full_audit.py
```

Consulta `scripts/full_audit_workflow.yml` para integrarlo en GitHub Actions.

---

## Flujo Maestro del Proyecto

```text
Raw validation ‚Üí Reverse Engineering (CLI) ‚Üí RAG Index ‚Üí Clustering (U1) ‚Üí Hypotheses (U2)
```

Cada etapa se ejecuta con su propio script CLI. Los resultados se encadenan para construir un laboratorio aut√≥nomo de descubrimiento.

| Subm√≥dulo | Prop√≥sito |
|-----------|-----------|
| `raw` | Datos crudos y validaci√≥n NDJSON |
| `reverse_engineering` | An√°lisis est√°tico de binarios |
| `rag_memory` | Indexaci√≥n vectorial de embeddings |
| `clusterer` | Agrupamiento inicial (U1) |
| `hypotheses` | Generaci√≥n de hip√≥tesis (U2) |

### Flujo de CI y del Motor

```
checkout ‚Üí setup-python ‚Üí install ‚Üí lint/tests ‚Üí orchestrate ‚Üí upload-artifacts
lint.yml         ‚Üí ejecuta pre-commit
tests.yml        ‚Üí instala dependencias y ejecuta pytest con cobertura
orchestrator.yml ‚Üí corre el orquestador y sube reportes

Collector ‚Üí Curator ‚Üí Kernel Builder Gen ‚Üí RAG Index
         ‚Üò                                   ‚Üó
           Orchestrator ‚Üí Reverse Engineering
```

## Capa de mensajer√≠a ZeroMQ

El proyecto incorpora una capa de comunicaci√≥n interna basada en **ZeroMQ** que
permite la interacci√≥n aut√≥noma entre los m√≥dulos `agent_loop`,
`kernel_unknown_engine`, `kernel_quantum`, `kernel_genomics_rag` y
`kernel_builder_gen`.

# Instalaci√≥n de dependencias

Para habilitar la mensajer√≠a distribuida basada en ZeroMQ y el entrenamiento de agentes de aprendizaje por refuerzo:
    pip install pyzmq
    pip install torch

# Configuraci√≥n de ZeroMQ

Todas las direcciones y par√°metros est√°n definidas en el archivo messaging_config.yaml en la ra√≠z del proyecto:
    defaults:
        timeout_ms: 2000  # espera m√°xima por operaci√≥n
        retries: 3        # intentos de reconexi√≥n
    pub_sub:
        address: tcp://127.0.0.1:5555
    push_pull:
        address: tcp://127.0.0.1:5556
    req_rep:
        address: tcp://127.0.0.1:5557
    metrics:
        address: tcp://127.0.0.1:5558

# Ejecuci√≥n distribuida

Cada agente (agent_loop, kernel_unknown_engine, kernel_quantum) se ejecuta en un proceso separado y todos comparten el bus de eventos mediante Pub/Sub, Push/Pull y Req/Rep.

# Agentes de Aprendizaje por Refuerzo Profundo (DQN)

Cada m√≥dulo cr√≠tico (agent_loop, kernel_unknown_engine, kernel_quantum) incluye un agente DQN que:
    - Aprende pol√≠ticas para procesar tareas seg√∫n el estado del sistema.
    - Almacena experiencias en experiences/*.pt.
    - Entrena modelos guardados en models/rl_agents/.

## Entrenamiento offline

    python train_rl_agents.py

## Entrenamiento continuo

    python continuous_trainer.py
Este proceso observa experiencias y actualiza pesos en segundo plano.

## Reinicio y exportaci√≥n

    python reset_agents.py          # reinicia modelos y buffers
    python export_metrics.py        # exporta m√©tricas a CSV o JSON

# M√©tricas y Dashboard

Los agentes publican m√©tricas en el canal metrics.  
El dashboard expone:
    /rl_metrics  -> historial de recompensas
    /zmq_metrics -> volumen y latencia de ZeroMQ

# Decisi√≥n en Orquestadores

Los orquestadores consultan a su rl_agent en cada ciclo para decidir si procesar inmediatamente, diferir o paralelizar tareas, mejorando el rendimiento a medida que se acumulan experiencias.

# Aprendizaje Federado y Cooperaci√≥n

Los agentes:
    - Comparten experiencias destacadas.
    - Participan en entrenamiento federado coordinado por rl_core/federated_trainer.py.
    - Env√≠an pesos por PUSH/PULL y reciben el modelo promedio por PUB/SUB.
    - Difunden experiencias de alto valor para acelerar el aprendizaje colectivo.
    - Negocian la ejecuci√≥n de tareas costosas por el canal cooperation (Req/Rep).

## Dashboard federado

    /federated_metrics       -> estado del modelo federado
    /shared_experiences      -> experiencias compartidas
    /cooperative_decisions   -> decisiones cooperativas

## Lanzar el entrenador federado

    python -m rl_core.federated_trainer

Para conectar nodos externos, ajustar messaging_config.yaml con IPs accesibles; se aceptan listas de direcciones para entornos multi-m√°quina.

# Orquestador Maestro

Permite ejecutar todos los m√≥dulos de forma orquestada:
    python -m kernel_brain_main.main --mode sequential
Para paralelizar etapas:
    python -m kernel_brain_main.main --mode parallel
Los eventos quedan registrados en logs/orchestrator_master.ndjson.

# Modos de Despliegue

## Local Runner (sin contenedores)

Arranca todos los servicios en una sola terminal:
    python -m local_runner --all

Ejecutar un subconjunto:
    python -m local_runner --only dashboard,agent_loop

## Ejecuci√≥n manual

Ejecutar cada servicio en terminales independientes, usando la misma configuraci√≥n de messaging_config.yaml.

```bash
python -m agent_loop.orchestrator
python -m kernel_quantum.orchestrator
python -m kernel_unknown_engine.main
python -m rl_core.federated_trainer
python -m dashboard.realtime_dashboard
```

### Docker Compose (una m√°quina)

```bash
docker-compose up --build
```

### LAN multi-m√°quina

Editar `messaging_config.yaml` con las IPs internas y lanzar servicios en
distintos equipos, por ejemplo:

```bash
docker-compose -f docker-compose.yaml up agent_loop federated_trainer
```

en la m√°quina 1 y

```bash
docker-compose -f docker-compose.yaml up kernel_quantum kernel_unknown_engine dashboard
```

en la m√°quina 2.

### Kubernetes (local o nube)

```bash
kubectl apply -f kubernetes/
```

### Soporte GPU

Los agentes detectan autom√°ticamente GPUs disponibles. Para forzar un dispositivo
espec√≠fico establecer la variable `BK_DEVICE`, por ejemplo `BK_DEVICE=cuda:0`.
Cuando hay m√∫ltiples GPUs se puede inicializar `torch.distributed` (backend
``nccl`` o ``gloo``) y el entrenador federado promediar√° pesos usando
`all_reduce`.
